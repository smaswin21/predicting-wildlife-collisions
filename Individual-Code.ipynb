{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66b64955",
   "metadata": {},
   "source": [
    "# **Individual Coding Project Code**\n",
    "\n",
    "- Student name: Aswin Subramanian Maheswaran"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44bcd188",
   "metadata": {},
   "source": [
    "##  **Project Title**: \n",
    "\n",
    "\n",
    "### **Objectives:**\n",
    "- \n",
    "\n",
    "### **Data sources:**\n",
    "\n",
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de6366f7",
   "metadata": {},
   "source": [
    "#### **I. Setup the environment:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e34863",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install necessary packages\n",
    "%pip install geopandas shapely pyproj tqdm plotly mapboxgl osmnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0c9ec902",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import osmnx as ox\n",
    "from shapely.geometry import Point, LineString\n",
    "from shapely.ops import split\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "# Scikit-learn (modeling & preprocessing)\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, average_precision_score, f1_score,\n",
    "    confusion_matrix, classification_report\n",
    ")\n",
    "\n",
    "# Imbalance handling and XGBoost\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Random seed\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "ox.settings.log_console = False\n",
    "ox.settings.use_cache = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99b1ee3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- spatial params ----\n",
    "\n",
    "CRS_LONLAT  = \"EPSG:4326\"\n",
    "CRS_METRIC  = \"EPSG:3857\"     # meters (for Spain)\n",
    "COUNTRY_CODE = \"ES\"\n",
    "FOCUS_BUF_M  = 1000           # 1 km focus window around GBIF points\n",
    "MATCH_MAX_M  = 200            # max distance GBIF -> segment to count as a match\n",
    "SEG_TARGET_M = 500            # ~500 m segment length\n",
    "INTERSECT_NEAR_M = 250        # radius to count nearby endpoints\n",
    "\n",
    "# ---- OSM fetch params ----\n",
    "OSM_TILE_DIST_M = 7000        # download 7 km circles around tile centroids\n",
    "ROUND_DEG = 0.1               # 11 km lat/lon rounding for GBIF tiling\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f32d8920",
   "metadata": {},
   "source": [
    "## **Part 1: Building the dataset - GeoDataFrame**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe90bff2",
   "metadata": {},
   "source": [
    "###    1.1 Clean the GBIF dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2ebb973",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBIF's Spain records after cleaning: 5050\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gbifID</th>\n",
       "      <th>occurrenceID</th>\n",
       "      <th>countryCode</th>\n",
       "      <th>decimalLatitude</th>\n",
       "      <th>decimalLongitude</th>\n",
       "      <th>eventDate</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>scientificName</th>\n",
       "      <th>basisOfRecord</th>\n",
       "      <th>coordinateUncertaintyInMeters</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>5100845320</td>\n",
       "      <td>060e8d29-0ad6-401d-a85f-97a0081d950c</td>\n",
       "      <td>ES</td>\n",
       "      <td>37.065452</td>\n",
       "      <td>-6.647498</td>\n",
       "      <td>2006-09-20</td>\n",
       "      <td>2006</td>\n",
       "      <td>9.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>Pelobates cultripes (Cuvier, 1829)</td>\n",
       "      <td>HUMAN_OBSERVATION</td>\n",
       "      <td>30.0</td>\n",
       "      <td>POINT (-739996.092 4448233.883)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>5100845353</td>\n",
       "      <td>985a81fc-6083-4429-bbbd-8bfcd09028e2</td>\n",
       "      <td>ES</td>\n",
       "      <td>37.356580</td>\n",
       "      <td>-6.341840</td>\n",
       "      <td>2011-04-09</td>\n",
       "      <td>2011</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Emberiza calandra Linnaeus, 1758</td>\n",
       "      <td>HUMAN_OBSERVATION</td>\n",
       "      <td>30.0</td>\n",
       "      <td>POINT (-705970.399 4488926.675)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        gbifID                          occurrenceID countryCode  \\\n",
       "18  5100845320  060e8d29-0ad6-401d-a85f-97a0081d950c          ES   \n",
       "51  5100845353  985a81fc-6083-4429-bbbd-8bfcd09028e2          ES   \n",
       "\n",
       "    decimalLatitude  decimalLongitude  eventDate  year  month   day  \\\n",
       "18        37.065452         -6.647498 2006-09-20  2006    9.0  20.0   \n",
       "51        37.356580         -6.341840 2011-04-09  2011    4.0   9.0   \n",
       "\n",
       "                        scientificName      basisOfRecord  \\\n",
       "18  Pelobates cultripes (Cuvier, 1829)  HUMAN_OBSERVATION   \n",
       "51    Emberiza calandra Linnaeus, 1758  HUMAN_OBSERVATION   \n",
       "\n",
       "    coordinateUncertaintyInMeters                         geometry  \n",
       "18                           30.0  POINT (-739996.092 4448233.883)  \n",
       "51                           30.0  POINT (-705970.399 4488926.675)  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GBIF_FILEPATH = \"data.csv\"\n",
    "\n",
    "GBIF_COLUMNS = [\n",
    "    \"gbifID\",\"occurrenceID\",\"countryCode\",\n",
    "    \"decimalLatitude\",\"decimalLongitude\",\n",
    "    \"eventDate\",\"year\",\"month\",\"day\",\n",
    "    \"scientificName\",\"basisOfRecord\",\"coordinateUncertaintyInMeters\"\n",
    "]\n",
    "\n",
    "road_kill = pd.read_csv(GBIF_FILEPATH, low_memory=False, sep='\\t', on_bad_lines='skip')\n",
    "road_kill = road_kill[[cols for cols in GBIF_COLUMNS if cols in road_kill.columns]].copy()\n",
    "\n",
    "\n",
    "# a. basic parsing and filters\n",
    "\n",
    "convert_to_numeric = lambda s: pd.to_numeric(s, errors=\"coerce\")\n",
    "road_kill[\"decimalLatitude\"] = convert_to_numeric(road_kill[\"decimalLatitude\"])\n",
    "road_kill[\"decimalLongitude\"] = convert_to_numeric(road_kill[\"decimalLongitude\"])\n",
    "road_kill[\"year\"] = convert_to_numeric(road_kill[\"year\"])\n",
    "road_kill[\"month\"] = convert_to_numeric(road_kill[\"month\"])\n",
    "road_kill[\"day\"] = convert_to_numeric(road_kill[\"day\"])\n",
    "\n",
    "# b. Parse eventDate\n",
    "\n",
    "road_kill[\"eventDate\"] = pd.to_datetime(road_kill[\"eventDate\"], errors=\"coerce\")\n",
    "fallback_date = pd.to_datetime(road_kill[[\"year\", \"month\", \"day\"]], errors=\"coerce\")\n",
    "# fill the missing eventDate with fallback_date\n",
    "road_kill[\"eventDate\"] = road_kill[\"eventDate\"].fillna(fallback_date)\n",
    "\n",
    "# c. Filter by country code\n",
    "\n",
    "filter_records = (\n",
    "    \n",
    "    (road_kill['countryCode'] == COUNTRY_CODE) &\n",
    "    road_kill['decimalLatitude'].between(-90, 90) & road_kill['decimalLongitude'].between(-180, 180)\n",
    ")\n",
    "\n",
    "road_kill = road_kill[filter_records].dropna(subset=['decimalLatitude','decimalLongitude']).copy()\n",
    "\n",
    "# d. Convert to GeoDataFrame and set CRS\n",
    "\n",
    "road_kill_gdf = gpd.GeoDataFrame(\n",
    "    road_kill, \n",
    "    geometry=gpd.points_from_xy(road_kill[\"decimalLongitude\"], road_kill[\"decimalLatitude\"]), \n",
    "    crs=CRS_LONLAT\n",
    ").to_crs(CRS_METRIC)\n",
    "\n",
    "\n",
    "print(f\"GBIF's Spain records after cleaning: {len(road_kill_gdf)}\")\n",
    "print()\n",
    "road_kill_gdf.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dead5d80",
   "metadata": {},
   "source": [
    "####    **Insights into the data**\n",
    "\n",
    "- **Challenge:** GBIF data is presence-only as it shows where animals were found dead, not where they weren't. This creates inherent bias.\n",
    "\n",
    "    -   The absence data is missing, we don't know where animals were not found, only where they were. \n",
    "    -   Sampling bias, as observations are focused in locations with more activity (human activity and road infrastructure). \n",
    "    -   This bias must be taken into account when training the predictive model, as the absence of observations do not necessarily demonstrate low risk. \n",
    "\n",
    "- **Mitigate the challenge:** Define a focus window around observed points to restrict our analysis to areas with sufficient coverage, rather than extrapolating to unsampled regions. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "373d973e",
   "metadata": {},
   "source": [
    "###    1.2 Focus-window and Area of Interest (AOI) \n",
    "\n",
    "**Aim**\n",
    "\n",
    "-   Define a spatial boundary around the recorded roadkill locations to restrict the analysis area and reduce the presence-only bias effect. \n",
    "-   Buffer Distance is 1 kilometer surrounding all GBIF observation points. \n",
    "-   Focuses analysis on areas with known survey coverage, avoiding predictions in unsampled regions. \n",
    "\n",
    "**Method** (for computational efficiency):\n",
    "\n",
    "-   **Tiling approach**: Round the coordinates to build 11 km tiles (ROUND_DEG = 0.1° ≈ 11 km at mid-latitudes)\n",
    "-   **Tile-based buffering**: Create 1 km buffers around each unique tile centroid instead of each individual data point. \n",
    "-   In the end, I combine all the buffers into one continuous AOI shape. \n",
    "\n",
    "**Why this approach?**\n",
    "\n",
    "- Much faster than buffering thousands of individual data points. \n",
    "- Reduces computational complexity from O(n) buffers to O(m) buffers where m << n (unique tiles)\n",
    "- Produces a continuous study area suitable for road network extraction. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f350b0fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[AOI] Focus window built (1 km around occupied tiles)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZcAAAF9CAYAAADIuSXpAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjEsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvc2/+5QAAAAlwSFlzAAAPYQAAD2EBqD+naQAAIntJREFUeJzt3Ql0XHXd//HvrFkn+9a06ZIu6V5oKUsptFAomywi4HKOD6jIX0VxYxH1iOjjysEFFEWPRz0o8jyIC8jaFiybQkuBFtKW7iVtlqbZM5nJLPd/vj+cPEm6pe2vM0nm/TonJLkzc+c3N+V+7m+9LsdxHAEAwCK3zZ0BAKAIFwCAdYQLAMA6wgUAYB3hAgCwjnABAFhHuAAArCNcAADWES4AAOsIF6Tcq6++Kn6/X3bt2jVg+1133SXV1dXi8XjkpJNOknTxzW9+U1wu17Df5+HU1taK1+uVt956K2nvieGFcElz9913nznpnHbaaYd93u7du+VTn/qUTJw4UTIyMqSsrEyuuOIKeemllw547j//+U+zzz//+c9DKsPXvvY1+fCHPywTJkzo2/bMM8/IrbfeKmeeeab89re/le9+97vH8OmQKjNnzpRLLrlEvvGNb6S6KEgRb6reGMPDH//4RxMYWnvYunWrTJky5YDnaIBcfPHF5ufrr7/enDgaGhrkd7/7nZx11lny05/+VD73uc8d0/u/8cYbsnLlSnn55ZcHbH/22WfF7XbLb37zG1OrSSdf//rX5Stf+YqMdHoxov9utm3bJpMnT051cZBk1FzS2I4dO8xJ/Uc/+pGUlpaaoBmstbVVrrrqKsnKypJ169bJ3XffLZ/4xCdMbWP9+vWyePFi+cIXvnBAOAyV1krGjx8vp59++oDtTU1N5j3TLViUNidlZmbKSHfeeedJYWGh/P73v091UZAChEsa0zDR//m1+UID5GDhcv/995taivZ/DL761JO/nji0Cexb3/rWMZXhb3/7m5x77rkD+gP0Zw2d7u5u87N+aS1JRaNR+fa3v23Kos1zWuv66le/KuFw+IB9P/nkk7JkyRIJBAKSl5cnCxculAcffLDvcX3tddddd8Drli5dar76u/fee2XWrFmSnZ1tjtkpp5wyYF+D6WLjJSUl8qUvfalvWzwel4KCAtOH1NbW1rf9Bz/4gQmUrq6uQ/aP6O+f/exnzfGaPXu2+exanqeeeuqA937xxRfNZ9WA0uOkf8ODGcqx1PIXFxebz5OgtVQtzz333NO3rbGx0Wz7xS9+0bfN5/OZ4/j3v//9kMcJoxfhksY0TK688kpTO9A+jy1btsiaNWsGPOexxx4zJ6lrrrnmoPuYNGmSqb1oM1ZPT89Rvf+ePXtMX878+fMHbH/ggQdMc5ue8PRn/Tr77LP7muW0HV9f8+Mf/9iEx/e+9z350Ic+NGAfGkYami0tLXL77bfL97//fTMo4GAn4yP59a9/LTfddJNpDvzJT34id955p9nXK6+8csjX6IlW+4uef/75vm1a02tvbzc/9++reuGFF+Tkk0+W3Nzcw5ZDQ+Mzn/mM+aw//OEPJRQKyQc+8AHZv39/33M2bNggy5cvNzU/DamPfexjcscdd8hf//rXA/Y3lGOpfwc9hm+//faA8mqTpX7vv00l/k4JCxYsMJ36HR0dh/1sGIX0fi5IP2vXrtVLUWfFihXm93g87owbN875/Oc/P+B5BQUFzrx58w67r5tuusnsa/369eb35557zvz+8MMPH/Z1K1euNM977LHHDnjs2muvdXJycgZse+ONN8zzr7/++gHbb775ZrP92WefNb+3tbU5gUDAOe2005yenp4Bz9XPmTBhwgTzPoMtWbLEfCVcfvnlzqxZs5yjdddddzkej8fp6Ogwv99zzz3mPU899VTntttuM9tisZg5xl/84hf7XnfHHXeYz9Of/u73+52tW7f2bXvzzTfN9nvvvbdv2xVXXOFkZmY6u3bt6ttWW1trytF/n0M9lk1NTeb3++67r+/Yut1u5+qrr3bKy8sH/BsoKioacHzVgw8+aF7/yiuvHPXxw8hGzSWNay3l5eVyzjnn9F1pf/CDH5SHHnpIYrFY3/M6OztNs9LhJB4/2qvTxBW3NjMNxRNPPGG+929qUl/+8pfN98cff9x8X7FihSm3dooP7rs4luG42pRVV1d3QK3uSPSqX49loj9Kr+51m34lrvT1ql6byHTbUPow+jdNzp071zT3bd++3fyu7/X000+bUXzaj5UwY8YMueCCC47pWGpf3PTp0/tqYFrj0ma9W265xTSFaW038dm0Bjv4+Cb+ts3NzUM+bhgdCJc0pCchDRENFu3U11Fi+qXDkfWEsWrVqgHBoSfqw0k8fqQQOpSh3gxV58Foc8zgEW0VFRUmABLzZHR0ktK+CRtuu+0202R16qmnytSpU+XGG2886BDswbS5SftoEkGSCBdtOlq7dq1p1ko8pifmI+kfGP1P3jroQu3bt880TWoZB6upqTmmY6n6h6F+1/4m/SoqKjK/60XFm2++edCATPxtkznHBsMD4ZKGtH+kvr7eBIyeiBJfiX6V/h37etW7efPmg3aY9+9L0M7bg53UDkc7ilXi5DhUtk5Uh9pP/5pb/2Ogx0tD4JFHHjHftS/jcPSYaGDrVb+Gtw6M0BOwvjYSiZg+Gz05a81AawhHojWGgzmeO5UP5VhqebV/TGtIiYDU1+l2/V1rZjpY4WDhkvjb6uAGpBfCJQ1peOgkyIcffviAL+3Y187fROf8+973PnOFrY8dzM6dO80JRkd86eixo6EnVaW1p6HQSZZ6Eks0xSRobUublhKTMBNNR0eaHa5X/f1HbSUMXilA5eTkmGZDHcWmgxB0sMB3vvMdc2wOR0+4OodI5/LoCVY/s17x60gvPW76NbgT/FhpQOnfYPDxURqOx3IsE58h0dyoTYOJ37Xcic+gx0c77wfTv63WkKZNm2blM2IESXWnD5IrGAyazu6Pf/zjB338pZdeMh2wDz30kPm9ubnZKSsrcyoqKpxt27YNeK52li9dutR08OrrEobaoa+qqqqcj370o0fVoX/DDTcM2H7rrbcO6IRub283n1E7zg/XoX/VVVeZTulwONy3TQcX6L76d+jrMRjslltuMZ870Vl/KDpgQvdXU1NjOtsTPv3pTzvTpk0zjz3wwAMDXnOoDv0bb7zxgP0PHpRwtB36RzqWCWPHjjWfweVyOS0tLWabdtLrc/VzLFu27KCf//3vf78zZ86cwx4jjE7M0E8zjz76qOkjueyyyw76uE5mTEyo1Ct1bbrSZVz0Sl37EAbP0NfmHp2hv2jRomMqz+WXX25qSnr+PFITzbx58+Taa6+VX/3qV+bqWofOaq1A59poJ3ZicIJ2cuvQWi2rzvf4yEc+Ymop2i8QDAb7JvXp4/rZLrzwQtMkqH01f/jDHw6Yz6NDe7UvQocW6yCIjRs3ys9+9jNzTI7Uz3TGGWeYOSxac7jhhhv6tutVf2JOyFA684dKh0nrcGvdpw5b1rksiTk62nx5tMcyQfenzYJz5szp66TXfw9aY3nnnXfMMR5Mm/5Wr15tyoE0lOp0Q3Jdeuml5sq2u7v7kM+57rrrHJ/PN+CKfceOHc4nP/lJZ/z48eaxkpIS57LLLnNeeOGFA15/NDWXdevWmecO3s/Bai4qEok4d955pzNp0iRTDq353H777U4oFDrguY8++qizaNEiJysry8nLyzM1mT/96U8DnnP33Xebq/KMjAznzDPPNEO0Bw9Fvv/++52zzz7bKS4uNs+bPHmyqbloDWkoFi5ceMBw3Lq6OrNNyz/Y8dRc1OrVq50FCxaYocvV1dXOL3/5y4Pu82iO5c9//nPzeq1x9XfeeeeZ7atWrTrgNU8++aR5bMuWLYc9PhidXPqfVAcc0tuyZcuksrLSTJbE6KE1IK2NHmwCJ0Y/wgUpp6OmtNlFO5f7dyRj5NKmQ21C04VJbQ0Jx8hCuAAArGMoMgDAOsIFAGAd4QIAsI5wAQBYR7gAAKwjXAAA1hEuAADrCBcAgHWECwDAOsIFAGAd4QIAsI5wAQBYR7gAAKwjXAAA1hEuAADrCBcAgHWECwDAOsIFAGAd4QIAsI5wAQCL2nsi8sSGeqlrDUo6I1wAwKI1O1pk+cxyeWlrs6QzwgUALApkeuWx9XulKCdD0hnhAgAWhaJxyc3wSSgSk3RGuACARdFYXBZNLpaOUETSmctxHCfVhQCAka4rHJVVGxulMxSRutYeWTylRBZPLZXhoLkrLC9v2y8luX5ZNLkkKe9JzQUALFizs0UuP2ms7NgXlJvPr5GGjrAMF+vr2uTSuWNM6CULNRcAsKAt2Cv/3LxP2np6pSQ3Q8rzMmXhxKLj3u/u/UHpjcVlSlnuAY/tbevpa37Ly/RJZUGW9PTGZMOedpk/vkC8nvfqD/XtPfLqjhbJz/LJ0poySQbCBQCG8ZyZ13e3SigSlxljAjKhOKfvsd5oXJ7d1Giek+nzSEdPRK4+pcoE3OyxeSZMrpw/LmVl96bsnQEAh+V2iTS0hyTD5zYB0p/LJbKvq1di8biprXg8bvG4XWaUmjZ/aU0mlQgXABiGHl9fLzHHkZmVeVJdmiu5GV55bVeLNLSHZXNDh0wtD5jmrkDGe6fxrq6wPPVWvWzf1yU9kZhMKz+wGS2Z6NAHgGEo2++Rc2pKZdf+oAkW1RaMyIWzK8zItDN11JcjUlWYLZNLcyUac2TptDLpDEflyvljZWdzapefoc8FAIaht/a0y+6WoJxTUyZZfk/fkOJXtreY4An2xiTL5zad/crvdUtPb9w8V5vJTqsuMgMLUoVwAQBYR58LAIwwsbgjrcFe01wWjr5Xc8nwuk1zWWG233TspxrhAgAjzCPr6mRMfqas3NgoE4tzRKNkR3O3LJtZZjr8rzmlKtVFpEMfAEaa3AyvlAcyxedxS5bPIwU5fu3bN537w2XBTPpcACBJdjR3m456bbpaPPXY1/haUdsgG+s7JBKLi1snvIhLinL8ZvLktPKABFI8x0VRcwGAJNnR3CWXzqs081OOh9ZYPnr6BBMqOt9FQ0VHhtVU5A2LYFH0uQBAEry8rdnMS/nO47WycGLhkNYU29LUaWo5UZ2FH4nL2IJMmVIWMEu/3PfPbZLpc5ua0NSyXCnI9vfNhxkOqLkAwAm2oa7ddLzrsvefWjLZLNtyJJsaOmR8UbYJJV2IUmfi/3t7iyR6Mj55VrVEYo5ZiXl8cY4sm1EuwwnhAgAnWHGuX17c2mx+1u9DqWHogpQaKp2hqHT2RKS2vsOsJ+ZyuczyLq/saDF9Llpz0ZFjww0d+gCQBM5/TrX6zT3EeSjdoaj85fU6M29l+cwKKQn834z7eNwxYaM0cIab4dNABwCjmOs/AXA0ORCO6VL7eab5SydN9g+XoQZUqtAsBgDDVFGO34wM83neGxU2ktAsBgCwjpoLAMA6wgUAYB3hAgCwjtFiADAMbGrokM0Nneb77MoCCWR65exppTJSUXMBgGGgoT0kF88ZI93hmCyfVS4NHSEZyRgtBgDDQDgak+c2NUlelk9auyOycFKhlAWG38z7oSJcAADW0ecCAIfRFuyVfZ1hyfR5zDIslQVZqS7SiEC4AMBhPL+lWTI8LtnV0iMFWT5ZNqNMinP/bxkWHBwd+gBwGB09EYnGHenpjZr1vLT2giOjzwUADkPvSa/L3/s9bhMu+Vk++de2/dLS3SsF2T45c8qx3654NKPmAgCHoX0t5XmZUpjjN8Gigr1RuWBWuextO77bFY9m1FyANKT3AnmmtlEccSQWd2RCUY7MGZef6mKNGK/tapEnNjTI5NIcM3R4aU3ZsLrF8HBAzQVIQ3qHQ72Pe+3eDjl9UpFsbOhIdZFGFG0mu/2i6bJtX7ecO71Mnt3UlOoiDTuEC5Bm2oMRc3+QR9bVSTQWl7+s2yNZPk+qizWi5Gb45Om3G00z2cqNTTJzTF6qizTsUI8D0qw5bNWmRonHRTK8HglH43LKxCJ5e297qos2opw6qSjVRRj2qLkAaaY3Gje32tVai956NxKLD/tb5mLkoUMfSDOdoYh0hqLidbvE73Wb/gMdDaWjogBbCBcAgHU0iwEArCNcAADWES4AAOsIFwCAdYQLAMA6wgUAYB3hAgCwjnABAFhHuAAArCNcAADWES4AAOsIFwCAddzPBUiDW/LWt4fE53HLBbMqUl0cpAlqLsAo1xaMyEWzx0hbsDfVRUEaYcl9YBRaUdsooUhMLppdIdv2dcn/rq2T8kCGVBZmyUlVBTKuMDvVRcQoR80FGGW0hlIayJA5Y/Nl7a5W2dPWI1+/ZIY0dobl/JnlsmZnS6qLiDRAzQUYBbSW8q9t+2VSSY7s2t8tG+s7pCcSl4UTCyUcicna3a1i7m3sODJ/fIEUZGfIwoncBx4nDjUXYBR4YUuzLJhYKL9+YbtUFWVLZzhmai/RuCOr32mW68+qlvbuXvnYokny8tYWyfZ75N/b96e62BjFCBdgFHC7RF7dsd9UTjY3dkqoNyodoYi82xIUcb03Ysztcskb77ZJNB43/TDFOf5UFxujGEORgVHA43ZJazAiZ00pkbOmlcr5M8ol5jjaCiZrd7bIvq6weD0u6QpHxON2S6g3bl4DnCjUXIBRIBJzzHBjDZhsv1e8HrdkeD2S6fNIOBo3j+lzzqkpM6GiTWh720KpLjZGMTr0gVGgOxw1/S6nVxdJfpZPHt9QL52hqHjdLmnviUhjR8gETjQWl/njCyWQ6ZMzpxSLS9vRgBOAmgswCuRkeOXC2RVSkO03kyarCrPF43LJuIIsEyw3L6+RSDQuN19QI6FoTBZPLSFYcEJRcwFGoafeqjc1li2NXZLld0tNRZ6pyQQyvTK7Ml8mluSkuogY5QgXYJR6dUeL1JQH5OnaBrnipLHi99JQgeThXxswSo3Jz5SVGxslGnPE56EJDMlFzQUAYB01FwCAdYQLAMA6wgUAYB3hAgCwjnABAFhHuAAArCNcAADWES4AAOsIFwCAdYQLAMA6wgUAYB3hAgCwjnABAFhHuAAArCNcAADWES4AAOsIFwCAdYQLAMA6wgUAYB3hAgCwjnABAFhHuAAArCNcAADWES7AKNHS3SvRWFzagr0SisSkKxxNdZGQxrypLgCA4/fM2w2Sm+GVf6yvl2UzyuSlrc0yr6pA5o8vlKqi7FQXD2mImgswCrhdLplSlmt+rizIlAyfRwqy/dLdS+0FqeFyHMdJ0XsDsOTf2/fLv7btl2BvVLJ8HukOR8Xndcu4wmzJ9nvkyvnjUl1EpBlqLsAo0NMbk5uWTZW4I/LhU8dLIMsn1SW5MqkkR/TysTcaT3URkWaouQCjwN62Hnl9d5t4PS6JxOLi97glFnck7jhSnJshp1cXp7qISDOECwDAOprFAADWES4AAOsIFwCAdYQLAMA6wgUAYB3LvwDHoTMUkSc3NJifr5w/Vl7d2SKt3RHZ0tQpVYVZ0tAektJAplx2UqVk+jypLi6QNNRcgOOwa39QltSUSknAbxaO1AUjl88ql85QVGaNzRe/1yOTy3Jkd0sw1UUFkopwAY7D9IqA/ObFHbK+rl3K8jLFLS75/pObJOY48j+vvivFAZ+090Rk6n/W/QLSBeECHIeN9Z1yw9nVclJVgWkCc1wiX7louvjcLrn5ghrxuj1y7vRycblcqS4qkFSEC3AcppbnyurN+6QtGJGyQIbkZfrkmbcbxet2yU9XvSMnVxVIOtJFNDfUtae6GEghln8BToAVtY0yrypf1u1qkwtnV0g62VjfITl+r7z+bqssrSmT/CxfqouEFKDmApwArcFec/VekO2T9mBE0klxjl9WbmyQfR0hs9w/0hPhApwA15xSJWdNKZE9rT3y3OYmaeoMSboI9saksiBLsjO8Eo3RMJKuCBfgBNFO/KIcv/lZl79PJ7rMf2LJf6Qn+lyAE2hPW4/E484h72Nf394jL23dL9v3dcmMMQEz+mxmZZ6Myc+UyaW58vTbDVLX2iPVpbni87jkfXMrZTh5bVeL1LeHJMPrkfNmlMn/rn1XQpG41Lf1SDgaN6PovB63XDJ3TKqLiiSj5gKcQGMLsg4ZLIlJmNrhH47GZNmMctOkdN6MctnZHDTBdPa0UhFHZNHkInPr4uFGR8ldNHuMtHb3SjTuyJj8LBlXmCUzxuRJlt8ti6eWSFc4vfqc8B5qLoAFOsdFl37p6IlIYbZfqktzzAn2SLRWs2pTk2T53NLeE5WCbK+0BaMSi8fNlf/bezskN9MrMysCMqU8INPKA5Jsmxo6ZFtTt1QVZcncce8Nre4KR2VlbaM0dYWkoS0sCyYUyCVzK+WXq7dJQ1uPeU4g0yfTxwSkRstelvxyI7VYWwywoLa+XS6dO0b++/GN8sGLquSxN/cOKVzcbpecP7N8wDbtq3h5W/N7j2u/Ta5fZo3JMysApII2e2nt6m+v7+kLl7U7W+Tykyrlu09slK9cVCOPvllvbq88Z2y+CUBdcy3b75X54wtM/wvSD+EC9KPrg+kQYp2jMq7w0M1Zg80cky+Pra+XScU5ZhLlUIKlv45QRF54p7mv5rJtX6cpi56og+GYlAZSd4LW/p+n3mowE0YTTplYJH9/Y6+ML8qWZ2obZWJxtvg8btN0p8vdaI1Mf08MaED6oVkM6Eebes6ZXiaPvFYn1yysStr7rtrYaCYcfvsftXLLBTXyk5XvyCcWV5sakS4fA4w0dOgD/QQyveYqPdk1hcIcvzz5Vr2ZdPjspiYzP+Qv6+qOu49lS2On7OsMSyrpYIV1u1slGountBxILmouwDCjTUqPb6iXktwMM/xYm6COxdt728UlLvn39v3yX2dMMEOCU0GHU+vq0Wt2tspVC8alpAxIPmouwFFIXH3rd70uOxGTI3Xfrd1hCfZGj/kGY1q2eFzMfBOvx5WySZz6WfQeN40dYcnxe6i9pBE69IEh0o7+tmCvvLJjv5w2qVhe2dEiJ48vkFmVedaG2uooM11ReUtTl7jdbplQnHPU++iNxuV/1uyWjlBUU0YaOkKmTyfqiFw2L3mTMHVEWVNnWNbtapWaiqhsbug0c2F0mPasyvyklQOpQc0FGCK9AtdO90jMkUWTi0Vv0TJ7bL4ZqmuL3+uWMyYXi9/jkdOri838maPVG4ubGf0632bOuHwz3PmsaaVmeHAydffq8So1gXLFyWPNNg3j+rb0WWctndHnAhxFjWD1O/tkfFGWmVm/bV+XWfH444snWZuD0tz13pW+znJvDUb+E2JHf6Ox2r0dsretR9buajGTGXVggC7FksyBCpvqO+Svr++RSDQuXq9bZlQEJJDllZauXvPZtCw6gOHC2SwNMxpRcwGOolahEx5rKvLMEi0zK/Pl/y2ZLOt2t1l7D+3EXz6rwuz7zCklx3wHS12fLMPnli8vr5HKgkxZMq006SPg9rb3yO0XzzCfQYdX61VsdUmunFZdbB7XsDNNdxiVqLkAx0hn0etERw2aY+14P9E1rWdqG0zzmAZVsul6Yy9ubTbNhzpqbe44nZiaZSZdao1PR7PpjcQ0rKeV58rUFCxtgxOHcAGQdM9tajL9Md/6R618/ZKZpvmMYcqjC+ECIOl0xWcdTaaDIaoKs6UsL0MWHuN8HgxPhAsAwDo69AEA1hEuAADrCBcAgHUs/wKkgK6x9dCad83ClLrEf1kgNTcCA04UwgVIgVA0LpNLcyUvyyt1rT2EC0YdwgVIAV0heM3OFnPnxpuWTT3g8cfX15v7oJxTU2bu9QKMNPS5ACnQ0ROVxVNL5COnjZf1de0DHtPl8bVGo8Hy6s6WlJUROB7UXIATRKeQrdzYJHHHkeUzywesE5af7ZPn39knHT0Rue3C6QMWnNze3CUb93bIqk1N8qXzpqWo9MDxoeYCnCDalzKpJEfKAhmyubFzwGPtPRE5a2qp/NcZEwcsfNnYEZJzp5dJzHHkpnOnmrtIAiMR4QKcIBX5mfL67lbZ2tRlQqa/vEyv7NrfLWt3tcrssXl927vCEfnxindMX8z9q7eZ+58AIxHLvwDDiN5vXm8Sds+qLfLR0yfI7pagnD2tNNXFAo4aNRcgBXe03NHcfdDHojFHXtiyz/TTrNv93k3DgJGImguQZI+8VieTy3LN/U50AuVg/f+XPNabhQGpxmgxIMk8br11lmNqJwdDoGA0oFkMSLJILC6v7myVgmwmR2L0IlyAJNNQuXrBOKlrDaa6KMAJQ58LkGTvtgRlY32HLK0pE7+X6zuMToQLAMA6LpsAANYRLgAA6wgXAIB1hAsAwDrCBQBgHeECALCOcAEAWEe4AACsI1wAANYRLgAA6wgXAIB1hAsAwDrCBQBgHeECALCOcAEAWEe4AACsI1wAANYRLgAA6wgXAIB1hAsAwDrCBQBgHeECALCOcAEAWEe4AACsI1wAANYRLgAA6wgXAIB1hAsAwDrCBQBgHeECALCOcAEAWEe4AACsI1wAANYRLgAA6wgXAIB1hAsAwDrCBQBgHeECALCOcAEAWEe4AACsI1wAANYRLgAA6wgXAIB1hAsAwDrCBQBgHeECALCOcAEAWEe4AACsI1wAANYRLgAA6wgXAIB1hAsAwDrCBQBgHeECALCOcAEAWEe4AACsI1wAANYRLgAA6wgXAIB1hAsAwDrCBQBgHeECALCOcAEAWEe4AACsI1wAANYRLgAA6wgXAIB1hAsAwDrCBQBgHeECALCOcAEAWEe4AACsI1wAANYRLgAA6wgXAIB1hAsAwDrCBQBgHeECALCOcAEAWEe4AACsI1wAANYRLgAA6wgXAIB1hAsAwDrCBQBgHeECALCOcAEAWEe4AACsI1wAANYRLgAA6wgXAIB1hAsAwDrCBQBgHeECALCOcAEAWEe4AACsI1wAANYRLgAA6wgXAIB1hAsAwDrCBQBgHeECALCOcAEAWEe4AACsI1wAANYRLgAA6wgXAIB1hAsAwDrCBQBgHeECALCOcAEAWEe4AACsI1wAANYRLgAA6wgXAIB1hAsAwDrCBQBgHeECALCOcAEAWEe4AACsI1wAANYRLgAA6wgXAIB1hAsAwDrCBQBgHeECALCOcAEAWEe4AACsI1wAANYRLgAA6wgXAIB1hAsAwDrCBQBgHeECALCOcAEAWEe4AACsI1wAANYRLgAA6wgXAIB1hAsAwDrCBQBgndf+LtOb4zjy8Gt10tMbk95YXPIyvXL1gipxu12pLhoAJA3hYpkGSmV+lgR7oxKOxsTtcktnOCr5Wb5UFw0AkoZwsWjVxkYJ9sbk+c1N4vW6JBYTKcrxy0WzK1JdNABIKsLFIrfLJUumlUjt3g45eUKBhCNx8bhd0hmKSn42NRcA6cPlaCcBjsub77bJu61BWbOjxfSttHT3SkGWT2ZV5sm4omxZNLkk1UUEgKRitJgF+7vDcvHsMeJ1u+WL502VsflZ8umlU6Q0kEmwAEhL1FyOQ1NnSF7c0ixbGrtM530g0ytTywPi87glHnfk/Jnl4vWQ3wDSD2e+47CpvlMunVdpguX2i2bIuMJsed/cSrlgVoVcNGcMwQIgbVFzOQ690bisqG0Ul0sk7jgytSwgNRWBVBcLAFKOcAEAWEe7DQDAOsIFAGAd4QIAsI5wAQBYR7gAAKwjXAAAI3fhyqaOkPxr+35p7gxLRX6WVORnyIIJRcl6ewDAaKy5vLW3XS6bVyl72nrkwtkVsrM5mKy3BgCM1kmUHaGIPLepSSKxuGT5vFJdmiMzxuQl460BAEnGDH0AgHV06AMArCNcAADWES4AAOsIFwCAdYQLAMA6wgUAYB3hAgCwjnABAFhHuAAArCNcAADWES4AAOsIFwCAdYQLAMA6wgUAYB3hAgCwjnABAFhHuAAArCNcAADWES4AAOsIFwCAdYQLAMA6wgUAYB3hAgAQ2/4/HbElO6KC3CwAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# -------------     Build Area of Interest (AOI) - Focus Window     ------------------\n",
    "\n",
    "# Convert all roadkill points to lat/lon coordinates\n",
    "\n",
    "all_points = road_kill_gdf.to_crs(CRS_LONLAT).copy()\n",
    "\n",
    "# Round coordinates to create spatial tiles (~11 km resolution)\n",
    "\n",
    "all_points[\"lat_round\"] = np.round(all_points.geometry.y / ROUND_DEG) * ROUND_DEG\n",
    "all_points[\"lon_round\"] = np.round(all_points.geometry.x / ROUND_DEG) * ROUND_DEG\n",
    "\n",
    "# Extract unique tile centroids (one point per tile)\n",
    "\n",
    "tiles = all_points[[\"lat_round\",\"lon_round\"]].drop_duplicates()\n",
    "tile_points = gpd.GeoDataFrame(\n",
    "    geometry=gpd.points_from_xy(tiles[\"lon_round\"], tiles[\"lat_round\"]),\n",
    "    crs=CRS_LONLAT\n",
    ").to_crs(CRS_METRIC)\n",
    "\n",
    "\n",
    "# Create GeoDataFrame of tile centroids and convert to metric CRS\n",
    "\n",
    "AOI = tile_points.buffer(FOCUS_BUF_M).union_all()\n",
    "AOI_gdf = gpd.GeoDataFrame(geometry=[AOI], crs=CRS_METRIC)\n",
    "\n",
    "# Buffer each tile centroid by 1 km and dissolve into single polygon\n",
    "# union_all() merges overlapping buffers into one continuous AOI\n",
    "\n",
    "print(\"[AOI] Focus window built (1 km around occupied tiles)\")\n",
    "AOI_gdf.boundary.plot(figsize=(5,5))\n",
    "plt.title(\"AOI (focus window)\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a6005d",
   "metadata": {},
   "source": [
    "### 1.3 OSM roads inside the focus-window (tile-based)\n",
    "\n",
    "**Aim**\n",
    "\n",
    "-   Extract drivable road network data from OpenStreetMap (OSM) within the Area of Interest (AOI) to serve as the spatial framework for collision risk analysis.\n",
    "\n",
    "**Road Classification**:\n",
    "\n",
    "- Filtering only to major road types: `motorway`, `trunk`, `primary`, `secondary`, `tertiary`, `residential`\n",
    "- These show the road hierarchy where most vehicle-wildlife collisions occur. \n",
    "\n",
    "**Data Quality**:\n",
    "- I have noticed that it is common to have missing OSM tags. \n",
    "- Fill the missing values with defaults based on road class. \n",
    "- Clip the final roads to AOI boundary to remove edge artifacts from tile downloads. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc582e95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OSM] roads in AOI: 3081\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>osmid</th>\n",
       "      <th>highway</th>\n",
       "      <th>lanes</th>\n",
       "      <th>maxspeed</th>\n",
       "      <th>name</th>\n",
       "      <th>oneway</th>\n",
       "      <th>ref</th>\n",
       "      <th>reversed</th>\n",
       "      <th>length</th>\n",
       "      <th>junction</th>\n",
       "      <th>bridge</th>\n",
       "      <th>tunnel</th>\n",
       "      <th>access</th>\n",
       "      <th>width</th>\n",
       "      <th>est_width</th>\n",
       "      <th>service</th>\n",
       "      <th>surface</th>\n",
       "      <th>highway_norm</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>88637472</td>\n",
       "      <td>tertiary</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Calle Siles</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>219.111468</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tertiary</td>\n",
       "      <td>LINESTRING (-488848 4452776.49, -488866.902 44...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1922</th>\n",
       "      <td>202398743</td>\n",
       "      <td>residential</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>9.882719</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>residential</td>\n",
       "      <td>LINESTRING (-1502121.264 3375622.043, -1502112...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019</th>\n",
       "      <td>1368769439</td>\n",
       "      <td>residential</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>16.540635</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>residential</td>\n",
       "      <td>LINESTRING (-1503633.15 3375595.455, -1503628....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           osmid      highway lanes maxspeed         name  oneway  ref  \\\n",
       "63      88637472     tertiary   NaN      NaN  Calle Siles   False  NaN   \n",
       "1922   202398743  residential   NaN      NaN          NaN   False  NaN   \n",
       "2019  1368769439  residential   NaN      NaN          NaN    True  NaN   \n",
       "\n",
       "     reversed      length junction bridge tunnel access width est_width  \\\n",
       "63      False  219.111468      NaN    NaN    NaN    NaN   NaN       NaN   \n",
       "1922     True    9.882719      NaN    NaN    NaN    NaN   NaN       NaN   \n",
       "2019    False   16.540635      NaN    NaN    NaN    NaN   NaN       NaN   \n",
       "\n",
       "     service  surface highway_norm  \\\n",
       "63       NaN      NaN     tertiary   \n",
       "1922     NaN      NaN  residential   \n",
       "2019     NaN      NaN  residential   \n",
       "\n",
       "                                               geometry  \n",
       "63    LINESTRING (-488848 4452776.49, -488866.902 44...  \n",
       "1922  LINESTRING (-1502121.264 3375622.043, -1502112...  \n",
       "2019  LINESTRING (-1503633.15 3375595.455, -1503628....  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#   -------     Download OSM Road Network (Tile-Based)  ----------\n",
    "\n",
    "roads_list = []\n",
    "\n",
    "# Iterating through each unique tile (from AOI creation step)\n",
    "\n",
    "for _, row in tiles.iterrows():\n",
    "    lat, lon = row[\"lat_round\"], row[\"lon_round\"]\n",
    "    try:\n",
    "        G = ox.graph_from_point((lat, lon), dist=OSM_TILE_DIST_M, network_type=\"drive\")\n",
    "        gdf = ox.graph_to_gdfs(G, nodes=False, edges=True)\n",
    "        roads_list.append(gdf)\n",
    "    except Exception as e:\n",
    "        continue\n",
    "\n",
    "roads = gpd.GeoDataFrame(pd.concat(roads_list, ignore_index=True), crs=CRS_LONLAT).to_crs(CRS_METRIC)\n",
    "\n",
    "for col in [\"highway\",\"maxspeed\",\"lanes\",\"oneway\",\"surface\",\"bridge\",\"tunnel\"]:\n",
    "    if col not in roads.columns:\n",
    "        roads[col] = np.nan\n",
    "\n",
    "def norm_highway(v):\n",
    "    return v[0] if isinstance(v, list) else v\n",
    "\n",
    "roads[\"highway_norm\"] = roads[\"highway\"].apply(norm_highway)\n",
    "valid_classes = {\"motorway\",\"trunk\",\"primary\",\"secondary\",\"tertiary\",\"residential\"}\n",
    "\n",
    "roads = roads[roads[\"highway_norm\"].isin(valid_classes)].copy()\n",
    "\n",
    "# clip to AOI to drop margins\n",
    "roads = gpd.overlay(roads, AOI_gdf, how=\"intersection\")\n",
    "\n",
    "# explode and clean\n",
    "roads = roads.explode(index_parts=False, ignore_index=True)\n",
    "roads = roads[~roads.geometry.is_empty & roads.geometry.notna()].copy()\n",
    "\n",
    "print(f\"[OSM] roads in AOI: {len(roads)}\")\n",
    "roads.sample(min(3, len(roads)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "758d21f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "roads.to_file(\"roads.gpkg\", driver=\"GPKG\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f9a2cf",
   "metadata": {},
   "source": [
    "####    Handle missing OSM tags with safe defaults (helps later):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b459acc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default by highway class (tuned to Spanish norms)\n",
    "\n",
    "DEFAULT_SPEED = {\"motorway\":120, \"trunk\":100, \"primary\":90, \"secondary\":80, \"tertiary\":60, \"residential\":30}\n",
    "DEFAULT_LANES = {\"motorway\":2, \"trunk\":2, \"primary\":2, \"secondary\":1, \"tertiary\":1, \"residential\":1}\n",
    "\n",
    "def parse_speed(x, cls):\n",
    "    if isinstance(x, list) and len(x): x = x[0]\n",
    "    if isinstance(x, str):\n",
    "        num = \"\".join(ch for ch in x if ch.isdigit())\n",
    "        x = int(num) if num else np.nan\n",
    "    try:\n",
    "        v = int(x)\n",
    "        return v if 10 <= v <= 140 else DEFAULT_SPEED.get(cls, 50)\n",
    "    except:\n",
    "        return DEFAULT_SPEED.get(cls, 50)\n",
    "\n",
    "def parse_lanes(x, cls):\n",
    "    if isinstance(x, list) and len(x): x = x[0]\n",
    "    try:\n",
    "        v = int(x)\n",
    "        return v if 1 <= v <= 6 else DEFAULT_LANES.get(cls, 1)\n",
    "    except:\n",
    "        return DEFAULT_LANES.get(cls, 1)\n",
    "\n",
    "roads[\"maxspeed_kph\"] = [parse_speed(x, c) for x, c in zip(roads[\"maxspeed\"], roads[\"highway_norm\"])]\n",
    "roads[\"n_lanes\"]      = [parse_lanes(x, c) for x, c in zip(roads[\"lanes\"], roads[\"highway_norm\"])]\n",
    "roads[\"is_oneway\"]    = roads[\"oneway\"].astype(\"bool\").fillna(False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c3a026",
   "metadata": {},
   "source": [
    "### 1.4 Segment Roads into 500 m Chunks\n",
    "\n",
    "**Aim**\n",
    "- Divide road network into uniform -500 m segments to create consistent analysis units for collision risk modeling.\n",
    "\n",
    "**Why do we segment**\n",
    "- It provides a fair comparison across different road types and identifies high-risk segments within longer roads. \n",
    "\n",
    "**Segment Features Calculated**:\n",
    "-   segment_length_m (Actual measured length of each segment)\n",
    "-   curve_index (Road curvature measure) : Higher values indicate sharper curves indicating potential collision hotspots. \n",
    "-   interaction_density (Count of nearby road endpoints per kilometer) : Gives insights into animal movement. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "25d6f175",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Segmenting: 100%|██████████| 3081/3081 [00:00<00:00, 18945.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Segments] built: 3352\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>segment_id</th>\n",
       "      <th>geometry</th>\n",
       "      <th>highway_norm</th>\n",
       "      <th>maxspeed_kph</th>\n",
       "      <th>n_lanes</th>\n",
       "      <th>is_oneway</th>\n",
       "      <th>surface</th>\n",
       "      <th>bridge</th>\n",
       "      <th>tunnel</th>\n",
       "      <th>segment_length_m</th>\n",
       "      <th>curve_index</th>\n",
       "      <th>intersection_density</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>LINESTRING (-700885.791 4494106.34, -701317.43...</td>\n",
       "      <td>secondary</td>\n",
       "      <td>90</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>431.64759</td>\n",
       "      <td>1.009614e-10</td>\n",
       "      <td>13.900196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>LINESTRING (-701317.533 4494108.559, -701352.3...</td>\n",
       "      <td>secondary</td>\n",
       "      <td>90</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>431.64759</td>\n",
       "      <td>4.679513e-07</td>\n",
       "      <td>13.900196</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   segment_id                                           geometry highway_norm  \\\n",
       "0           0  LINESTRING (-700885.791 4494106.34, -701317.43...    secondary   \n",
       "1           1  LINESTRING (-701317.533 4494108.559, -701352.3...    secondary   \n",
       "\n",
       "   maxspeed_kph  n_lanes  is_oneway  surface bridge tunnel  segment_length_m  \\\n",
       "0            90        2      False      NaN    NaN    NaN         431.64759   \n",
       "1            90        2      False      NaN    NaN    NaN         431.64759   \n",
       "\n",
       "    curve_index  intersection_density  \n",
       "0  1.009614e-10             13.900196  \n",
       "1  4.679513e-07             13.900196  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def segment_line(line: LineString, target_m=SEG_TARGET_M):\n",
    "    \"\"\"\n",
    "    Split a LineString into segments of approximately target_m length.\n",
    "    \"\"\"\n",
    "    \n",
    "    # It handles non-LineString geometries\n",
    "    \n",
    "    if not isinstance(line, LineString): \n",
    "        return []\n",
    "    \n",
    "    # If line is already shorter than target, return as-is\n",
    "    if line.length <= target_m: \n",
    "        return [line]\n",
    "    \n",
    "    # Calculate number of segments needed\n",
    "    n = int(np.ceil(line.length / target_m))\n",
    "    dists = [i * line.length / n for i in range(1, n)]\n",
    "    \n",
    "    # Split line at each distance point\n",
    "    pieces = [line]\n",
    "    for d in dists:\n",
    "        p = line.interpolate(d)\n",
    "        tiny = p.buffer(0.05)\n",
    "        new_pieces = []\n",
    "        for seg in pieces:\n",
    "            try:\n",
    "                parts = split(seg, tiny)\n",
    "                new_pieces.extend([g for g in parts.geoms if isinstance(g, LineString)])\n",
    "            except Exception:\n",
    "                new_pieces.append(seg)\n",
    "        pieces = new_pieces\n",
    "    return [s for s in pieces if s.length > 1]\n",
    "\n",
    "# build segments table\n",
    "\n",
    "seg_rows, sid = [], 0\n",
    "for _, r in tqdm(roads.iterrows(), total=len(roads), desc=\"Segmenting\"):\n",
    "    for seg in segment_line(r.geometry):\n",
    "        seg_rows.append({\n",
    "            \"segment_id\": sid,\n",
    "            \"geometry\": seg,\n",
    "            \"highway_norm\": r[\"highway_norm\"],\n",
    "            \"maxspeed_kph\": r[\"maxspeed_kph\"],\n",
    "            \"n_lanes\": r[\"n_lanes\"],\n",
    "            \"is_oneway\": r[\"is_oneway\"],\n",
    "            \"surface\": r[\"surface\"],\n",
    "            \"bridge\": r[\"bridge\"],\n",
    "            \"tunnel\": r[\"tunnel\"],\n",
    "        })\n",
    "        sid += 1\n",
    "\n",
    "segments = gpd.GeoDataFrame(seg_rows, crs=roads.crs)\n",
    "segments[\"segment_length_m\"] = segments.geometry.length\n",
    "\n",
    "# curvature proxy (bearing change per meter)\n",
    "\n",
    "def curve_index(line: LineString, step=20):\n",
    "    L = line.length\n",
    "    if L < 2*step: return 0.0\n",
    "    d = np.arange(0, L, step)\n",
    "    pts = [line.interpolate(x) for x in d] + [line.interpolate(L)]\n",
    "    bearings = []\n",
    "    for p0, p1 in zip(pts[:-1], pts[1:]):\n",
    "        dx, dy = (p1.x - p0.x), (p1.y - p0.y)\n",
    "        bearings.append(np.degrees(np.arctan2(dy, dx)))\n",
    "    diffs = np.abs(np.diff(bearings))\n",
    "    diffs = np.minimum(diffs, 360 - diffs)\n",
    "    return float(diffs.sum() / max(L, 1))\n",
    "\n",
    "segments[\"curve_index\"] = segments.geometry.apply(curve_index)\n",
    "\n",
    "# intersection density: count endpoints within radius per km\n",
    "\n",
    "endpoints = []\n",
    "for g in segments.geometry:\n",
    "    xs, ys = g.coords.xy\n",
    "    endpoints.append(Point(xs[0], ys[0]))\n",
    "    endpoints.append(Point(xs[-1], ys[-1]))\n",
    "end_gdf = gpd.GeoDataFrame(geometry=endpoints, crs=segments.crs)\n",
    "\n",
    "midpts = segments.geometry.interpolate(0.5, normalized=True)\n",
    "mid_gdf = gpd.GeoDataFrame(segments[[\"segment_id\"]], geometry=midpts, crs=segments.crs)\n",
    "\n",
    "# buffer once, spatial join\n",
    "\n",
    "near = gpd.sjoin(\n",
    "    end_gdf,\n",
    "    gpd.GeoDataFrame(geometry=mid_gdf.buffer(INTERSECT_NEAR_M), crs=segments.crs),\n",
    "    how=\"left\", predicate=\"within\"\n",
    ")\n",
    "\n",
    "counts = near.groupby(near.index_right).size()\n",
    "segments[\"intersection_density\"] = counts.reindex(range(len(segments))).fillna(0).values / (segments[\"segment_length_m\"]/1000 + 1e-6)\n",
    "\n",
    "print(f\"[Segments] built: {len(segments)}\")\n",
    "segments.head(2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8559080b",
   "metadata": {},
   "source": [
    "### 1.5 Label creation (nearest-segment match ≤ 200 m)\n",
    "\n",
    "**Aim**\n",
    "- Create the binary labels (collision_risk) by matching roadkill observations to nearest road segments.\n",
    "\n",
    "**Method:**\n",
    "\n",
    "-   Use a nearest-neighbor spatial join with a 200 m maximum distance to handle GBIF GPS uncertainty.\n",
    "-   A segment is positive (1) if ≥1 collision falls within 200 m; otherwise negative (0).\n",
    "\n",
    "**Label Outputs:**\n",
    "\n",
    "-   collision_count: Number of matched collisions\n",
    "-   collision_risk: 1 if collision_count > 0, else 0\n",
    "\n",
    "**Why 200 m?**\n",
    "\n",
    "-   Roadkill often recorded slightly off-road.\n",
    "-   200 m provides good precision–recall balance and sensitivity tests show little gain beyond this distance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "31ea7865",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensure both in same CRS\n",
    "assert road_kill_gdf.crs == segments.crs == CRS_METRIC\n",
    "\n",
    "# nearest join (fast with sindex). geopandas>=0.10 has sjoin_nearest\n",
    "joined = gpd.sjoin_nearest(\n",
    "    road_kill_gdf[[\"gbifID\",\"eventDate\",\"geometry\"]],\n",
    "    segments[[\"segment_id\",\"geometry\"]],\n",
    "    how=\"inner\", \n",
    "    max_distance=MATCH_MAX_M, \n",
    "    distance_col=\"dist_m\"\n",
    ")\n",
    "\n",
    "# aggregate counts per segment\n",
    "counts = joined.groupby(\"segment_id\").size().rename(\"collision_count\")\n",
    "segments = segments.join(counts, on=\"segment_id\")\n",
    "segments[\"collision_count\"] = segments[\"collision_count\"].fillna(0).astype(int)\n",
    "segments[\"collision_risk\"]  = (segments[\"collision_count\"] > 0).astype(int)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8cdb3fa",
   "metadata": {},
   "source": [
    "## **Part 2: Predictive Modelling**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86909047",
   "metadata": {},
   "source": [
    "### 2.1 Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f271da08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (3352, 10), positives: 52 (1.55%)\n"
     ]
    }
   ],
   "source": [
    "def prepare_modeling_data(segments, target_col=\"collision_risk\"):\n",
    "    \n",
    "    \"\"\"\n",
    "    Prepare data for modeling by extracting features and target.\n",
    "    \"\"\"\n",
    "    \n",
    "    numerical_cols = [\n",
    "        \"segment_length_m\", \"curve_index\", \"intersection_density\",\n",
    "        \"maxspeed_kph\", \"n_lanes\"\n",
    "    ]\n",
    "    \n",
    "    categorical_cols = [\"highway_norm\", \"is_oneway\", \"surface\", \"bridge\", \"tunnel\"]\n",
    "    \n",
    "    df = segments.drop(columns=[\"geometry\", \"buffer_geom\"], errors=\"ignore\").copy()\n",
    "    df[target_col] = df[target_col].astype(int)\n",
    "    \n",
    "    # Handle categorical columns (convert lists to strings)\n",
    "    for col in categorical_cols:\n",
    "        if col in df.columns:\n",
    "            df[col] = df[col].apply(lambda x: x[0] if isinstance(x, list) else x)\n",
    "            df[col] = df[col].astype(str)\n",
    "    \n",
    "    X = df[numerical_cols + categorical_cols]\n",
    "    y = df[target_col].values\n",
    "    \n",
    "    feature_info = {\"numerical\": numerical_cols, \"categorical\": categorical_cols}\n",
    "    return X, y, feature_info\n",
    "\n",
    "\n",
    "X, y, feature_info = prepare_modeling_data(segments)\n",
    "numerical_cols = feature_info[\"numerical\"]\n",
    "categorical_cols = feature_info[\"categorical\"]\n",
    "\n",
    "print(f\"Dataset shape: {X.shape}, positives: {y.sum()} ({y.mean():.2%})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd42809",
   "metadata": {},
   "source": [
    "### 2.2     Build Preprocessing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3364f4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_preprocessor(numerical_cols, categorical_cols):\n",
    "    \"\"\"\n",
    "    Build preprocessing pipeline for numerical and categorical features.\n",
    "    \"\"\"\n",
    "    numeric_tf = Pipeline(steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    ])\n",
    "    categorical_tf = Pipeline(steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "        (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False))\n",
    "    ])\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"num\", numeric_tf, numerical_cols),\n",
    "            (\"cat\", categorical_tf, categorical_cols),\n",
    "        ]\n",
    "    )\n",
    "    return preprocessor\n",
    "\n",
    "preprocessor = build_preprocessor(numerical_cols, categorical_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9239a51",
   "metadata": {},
   "source": [
    "### 2.3 Helper Functions: Class Imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca00966d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class imbalance ratio: 63.5:1\n"
     ]
    }
   ],
   "source": [
    "def calculate_imbalance_ratio(y):\n",
    "    \"\"\"Calculate class imbalance ratio (negative:positive).\"\"\"\n",
    "    n_neg = (y == 0).sum()\n",
    "    n_pos = (y == 1).sum()\n",
    "    return n_neg / n_pos if n_pos > 0 else 0\n",
    "\n",
    "imbalance_ratio = calculate_imbalance_ratio(y)\n",
    "print(f\"Class imbalance ratio: {imbalance_ratio:.1f}:1\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d606433",
   "metadata": {},
   "source": [
    "### 2.4 Building the models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af06b69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built 8 models\n"
     ]
    }
   ],
   "source": [
    "def build_models(preprocessor, y, random_state=42):\n",
    "    \"\"\"\n",
    "    Build all models (Logistic Regression, Random Forest, Decision Tree, XGBoost) with two strategies:\n",
    "    - 1. class_weight\n",
    "    - 2. oversampling strategy\n",
    "    \"\"\"\n",
    "    models = {}\n",
    "    scale_pos_weight = calculate_imbalance_ratio(y)\n",
    "    \n",
    "    oversampler = RandomOverSampler(\n",
    "        random_state=random_state,\n",
    "        sampling_strategy=1.0\n",
    "    )\n",
    "\n",
    "    def add_model_pair(name, estimator_class, base_params,\n",
    "                       use_class_weight=False, is_xgb=False):\n",
    "        \"\"\"\n",
    "        Add two variants for a given estimator:\n",
    "        - {name}_class_weight\n",
    "        - {name}_oversample\n",
    "        \"\"\"\n",
    "        # --- class_weight / scale_pos_weight variant ---\n",
    "        params_cw = base_params.copy()\n",
    "        if use_class_weight and not is_xgb:\n",
    "            params_cw[\"class_weight\"] = \"balanced\"\n",
    "        if is_xgb:\n",
    "            params_cw[\"scale_pos_weight\"] = scale_pos_weight\n",
    "        \n",
    "        clf_cw = estimator_class(**params_cw)\n",
    "        models[f\"{name}_class_weight\"] = Pipeline(steps=[\n",
    "            (\"prep\", preprocessor),\n",
    "            (\"clf\", clf_cw)\n",
    "        ])\n",
    "        \n",
    "        # --- oversample variant ---\n",
    "        params_os = base_params.copy()\n",
    "        if use_class_weight and not is_xgb:\n",
    "            params_os[\"class_weight\"] = \"balanced\"\n",
    "        if is_xgb:\n",
    "            # after oversampling, classes are balanced\n",
    "            params_os[\"scale_pos_weight\"] = 1.0\n",
    "        \n",
    "        clf_os = estimator_class(**params_os)\n",
    "        models[f\"{name}_oversample\"] = ImbPipeline(steps=[\n",
    "            (\"prep\", preprocessor),\n",
    "            (\"oversample\", oversampler),\n",
    "            (\"clf\", clf_os)\n",
    "        ])\n",
    "    \n",
    "    # Logistic Regression\n",
    "    add_model_pair(\n",
    "        name=\"logreg\",\n",
    "        estimator_class=LogisticRegression,\n",
    "        base_params=dict(\n",
    "            max_iter=2000,\n",
    "            solver=\"lbfgs\",\n",
    "            C=0.1,\n",
    "            random_state=random_state\n",
    "        ),\n",
    "        use_class_weight=True,\n",
    "        is_xgb=False\n",
    "    )\n",
    "    \n",
    "    # Random Forest\n",
    "    add_model_pair(\n",
    "        name=\"rf\",\n",
    "        estimator_class=RandomForestClassifier,\n",
    "        base_params=dict(\n",
    "            n_estimators=200,\n",
    "            max_depth=10,\n",
    "            min_samples_split=20,\n",
    "            min_samples_leaf=10,\n",
    "            random_state=random_state,\n",
    "            n_jobs=-1\n",
    "        ),\n",
    "        use_class_weight=True,\n",
    "        is_xgb=False\n",
    "    )\n",
    "    \n",
    "    # Decision Tree\n",
    "    add_model_pair(\n",
    "        name=\"dt\",\n",
    "        estimator_class=DecisionTreeClassifier,\n",
    "        base_params=dict(\n",
    "            max_depth=10,\n",
    "            min_samples_split=20,\n",
    "            min_samples_leaf=10,\n",
    "            random_state=random_state\n",
    "        ),\n",
    "        use_class_weight=True,\n",
    "        is_xgb=False\n",
    "    )\n",
    "    \n",
    "    # XGBoost\n",
    "    add_model_pair(\n",
    "        name=\"xgb\",\n",
    "        estimator_class=XGBClassifier,\n",
    "        base_params=dict(\n",
    "            n_estimators=200,\n",
    "            max_depth=6,\n",
    "            learning_rate=0.1,\n",
    "            subsample=0.8,\n",
    "            colsample_bytree=0.8,\n",
    "            min_child_weight=5,\n",
    "            eval_metric=\"logloss\",\n",
    "            random_state=random_state,\n",
    "            n_jobs=-1,\n",
    "            verbosity=0\n",
    "        ),\n",
    "        use_class_weight=False,\n",
    "        is_xgb=True\n",
    "    )\n",
    "    \n",
    "    return models\n",
    "\n",
    "\n",
    "# Build all models \n",
    "\n",
    "all_models = build_models(preprocessor, y, RANDOM_SEED)\n",
    "print(f\"Built {len(all_models)} models\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc7a4d7c",
   "metadata": {},
   "source": [
    "##  **Part 3 — Model Evaluation**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dcc420d",
   "metadata": {},
   "source": [
    "### 3.1 Cross-Validation Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cec421b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 2000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=2000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cross-Validation Results: filtered by their PR-AUC \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_f5abb\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_f5abb_level0_col0\" class=\"col_heading level0 col0\" >model</th>\n",
       "      <th id=\"T_f5abb_level0_col1\" class=\"col_heading level0 col1\" >pr_auc_mean</th>\n",
       "      <th id=\"T_f5abb_level0_col2\" class=\"col_heading level0 col2\" >pr_auc_std</th>\n",
       "      <th id=\"T_f5abb_level0_col3\" class=\"col_heading level0 col3\" >roc_auc_mean</th>\n",
       "      <th id=\"T_f5abb_level0_col4\" class=\"col_heading level0 col4\" >roc_auc_std</th>\n",
       "      <th id=\"T_f5abb_level0_col5\" class=\"col_heading level0 col5\" >f1_mean</th>\n",
       "      <th id=\"T_f5abb_level0_col6\" class=\"col_heading level0 col6\" >f1_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_f5abb_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_f5abb_row0_col0\" class=\"data row0 col0\" >xgb_class_weight</td>\n",
       "      <td id=\"T_f5abb_row0_col1\" class=\"data row0 col1\" >0.818</td>\n",
       "      <td id=\"T_f5abb_row0_col2\" class=\"data row0 col2\" >0.091</td>\n",
       "      <td id=\"T_f5abb_row0_col3\" class=\"data row0 col3\" >0.977</td>\n",
       "      <td id=\"T_f5abb_row0_col4\" class=\"data row0 col4\" >0.033</td>\n",
       "      <td id=\"T_f5abb_row0_col5\" class=\"data row0 col5\" >0.756</td>\n",
       "      <td id=\"T_f5abb_row0_col6\" class=\"data row0 col6\" >0.081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f5abb_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_f5abb_row1_col0\" class=\"data row1 col0\" >xgb_oversample</td>\n",
       "      <td id=\"T_f5abb_row1_col1\" class=\"data row1 col1\" >0.778</td>\n",
       "      <td id=\"T_f5abb_row1_col2\" class=\"data row1 col2\" >0.100</td>\n",
       "      <td id=\"T_f5abb_row1_col3\" class=\"data row1 col3\" >0.972</td>\n",
       "      <td id=\"T_f5abb_row1_col4\" class=\"data row1 col4\" >0.035</td>\n",
       "      <td id=\"T_f5abb_row1_col5\" class=\"data row1 col5\" >0.736</td>\n",
       "      <td id=\"T_f5abb_row1_col6\" class=\"data row1 col6\" >0.089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f5abb_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_f5abb_row2_col0\" class=\"data row2 col0\" >rf_oversample</td>\n",
       "      <td id=\"T_f5abb_row2_col1\" class=\"data row2 col1\" >0.659</td>\n",
       "      <td id=\"T_f5abb_row2_col2\" class=\"data row2 col2\" >0.090</td>\n",
       "      <td id=\"T_f5abb_row2_col3\" class=\"data row2 col3\" >0.972</td>\n",
       "      <td id=\"T_f5abb_row2_col4\" class=\"data row2 col4\" >0.031</td>\n",
       "      <td id=\"T_f5abb_row2_col5\" class=\"data row2 col5\" >0.533</td>\n",
       "      <td id=\"T_f5abb_row2_col6\" class=\"data row2 col6\" >0.060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f5abb_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_f5abb_row3_col0\" class=\"data row3 col0\" >rf_class_weight</td>\n",
       "      <td id=\"T_f5abb_row3_col1\" class=\"data row3 col1\" >0.545</td>\n",
       "      <td id=\"T_f5abb_row3_col2\" class=\"data row3 col2\" >0.093</td>\n",
       "      <td id=\"T_f5abb_row3_col3\" class=\"data row3 col3\" >0.972</td>\n",
       "      <td id=\"T_f5abb_row3_col4\" class=\"data row3 col4\" >0.021</td>\n",
       "      <td id=\"T_f5abb_row3_col5\" class=\"data row3 col5\" >0.490</td>\n",
       "      <td id=\"T_f5abb_row3_col6\" class=\"data row3 col6\" >0.082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f5abb_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_f5abb_row4_col0\" class=\"data row4 col0\" >dt_oversample</td>\n",
       "      <td id=\"T_f5abb_row4_col1\" class=\"data row4 col1\" >0.423</td>\n",
       "      <td id=\"T_f5abb_row4_col2\" class=\"data row4 col2\" >0.094</td>\n",
       "      <td id=\"T_f5abb_row4_col3\" class=\"data row4 col3\" >0.924</td>\n",
       "      <td id=\"T_f5abb_row4_col4\" class=\"data row4 col4\" >0.089</td>\n",
       "      <td id=\"T_f5abb_row4_col5\" class=\"data row4 col5\" >0.442</td>\n",
       "      <td id=\"T_f5abb_row4_col6\" class=\"data row4 col6\" >0.073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f5abb_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_f5abb_row5_col0\" class=\"data row5 col0\" >dt_class_weight</td>\n",
       "      <td id=\"T_f5abb_row5_col1\" class=\"data row5 col1\" >0.344</td>\n",
       "      <td id=\"T_f5abb_row5_col2\" class=\"data row5 col2\" >0.088</td>\n",
       "      <td id=\"T_f5abb_row5_col3\" class=\"data row5 col3\" >0.915</td>\n",
       "      <td id=\"T_f5abb_row5_col4\" class=\"data row5 col4\" >0.070</td>\n",
       "      <td id=\"T_f5abb_row5_col5\" class=\"data row5 col5\" >0.319</td>\n",
       "      <td id=\"T_f5abb_row5_col6\" class=\"data row5 col6\" >0.049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f5abb_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_f5abb_row6_col0\" class=\"data row6 col0\" >logreg_class_weight</td>\n",
       "      <td id=\"T_f5abb_row6_col1\" class=\"data row6 col1\" >0.151</td>\n",
       "      <td id=\"T_f5abb_row6_col2\" class=\"data row6 col2\" >0.062</td>\n",
       "      <td id=\"T_f5abb_row6_col3\" class=\"data row6 col3\" >0.890</td>\n",
       "      <td id=\"T_f5abb_row6_col4\" class=\"data row6 col4\" >0.037</td>\n",
       "      <td id=\"T_f5abb_row6_col5\" class=\"data row6 col5\" >0.134</td>\n",
       "      <td id=\"T_f5abb_row6_col6\" class=\"data row6 col6\" >0.021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f5abb_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_f5abb_row7_col0\" class=\"data row7 col0\" >logreg_oversample</td>\n",
       "      <td id=\"T_f5abb_row7_col1\" class=\"data row7 col1\" >0.120</td>\n",
       "      <td id=\"T_f5abb_row7_col2\" class=\"data row7 col2\" >0.043</td>\n",
       "      <td id=\"T_f5abb_row7_col3\" class=\"data row7 col3\" >0.889</td>\n",
       "      <td id=\"T_f5abb_row7_col4\" class=\"data row7 col4\" >0.034</td>\n",
       "      <td id=\"T_f5abb_row7_col5\" class=\"data row7 col5\" >0.131</td>\n",
       "      <td id=\"T_f5abb_row7_col6\" class=\"data row7 col6\" >0.022</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x32afc4490>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def evaluate_models_cv(models, X, y, n_splits=5, random_state=42):\n",
    "    \"\"\"\n",
    "    Evaluate models using stratified k-fold cross-validation.\n",
    "    \"\"\"\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "    rows = []\n",
    "    \n",
    "    for name, pipe in models.items():\n",
    "        rocs, prs, f1s = [], [], []\n",
    "        for tr_idx, te_idx in skf.split(X, y):\n",
    "            X_tr, X_te = X.iloc[tr_idx], X.iloc[te_idx]\n",
    "            y_tr, y_te = y[tr_idx], y[te_idx]\n",
    "            \n",
    "            pipe.fit(X_tr, y_tr)\n",
    "            y_prob = pipe.predict_proba(X_te)[:, 1]\n",
    "            y_pred = (y_prob >= 0.5).astype(int)\n",
    "            \n",
    "            rocs.append(roc_auc_score(y_te, y_prob))\n",
    "            prs.append(average_precision_score(y_te, y_prob))\n",
    "            f1s.append(f1_score(y_te, y_pred))\n",
    "        \n",
    "        rows.append({\n",
    "            \"model\": name,\n",
    "            \"pr_auc_mean\": np.mean(prs),\n",
    "            \"pr_auc_std\": np.std(prs),\n",
    "            \"roc_auc_mean\": np.mean(rocs),\n",
    "            \"roc_auc_std\": np.std(rocs),\n",
    "            \"f1_mean\": np.mean(f1s),\n",
    "            \"f1_std\": np.std(f1s),\n",
    "        })\n",
    "    \n",
    "    res = pd.DataFrame(rows).sort_values(\"pr_auc_mean\", ascending=False).reset_index(drop=True)\n",
    "    return res\n",
    "\n",
    "cv_results = evaluate_models_cv(all_models, X, y, n_splits=5, random_state=RANDOM_SEED)\n",
    "\n",
    "print()\n",
    "print(\"Cross-Validation Results: filtered by their PR-AUC \")\n",
    "print()\n",
    "display(cv_results.style.format({\n",
    "    \"pr_auc_mean\": \"{:.3f}\", \"pr_auc_std\": \"{:.3f}\",\n",
    "    \"roc_auc_mean\": \"{:.3f}\", \"roc_auc_std\": \"{:.3f}\",\n",
    "    \"f1_mean\": \"{:.3f}\", \"f1_std\": \"{:.3f}\"\n",
    "}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78af0f2e",
   "metadata": {},
   "source": [
    "### 3.2     Choose the select model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "29d6101a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best model: xgb_class_weight\n",
      "  PR-AUC: 0.818 ± 0.091\n",
      "  ROC-AUC: 0.977 ± 0.033\n",
      "  F1: 0.756 ± 0.081\n"
     ]
    }
   ],
   "source": [
    "def select_best_model(cv_results, models):\n",
    "    \"\"\"\n",
    "    Select best model based on PR-AUC score.\n",
    "    \"\"\"\n",
    "    best_model_name = cv_results.iloc[0][\"model\"]\n",
    "    best_model = models[best_model_name]\n",
    "    print(f\"\\nBest model: {best_model_name}\")\n",
    "    print(f\"  PR-AUC: {cv_results.iloc[0]['pr_auc_mean']:.3f} ± {cv_results.iloc[0]['pr_auc_std']:.3f}\")\n",
    "    print(f\"  ROC-AUC: {cv_results.iloc[0]['roc_auc_mean']:.3f} ± {cv_results.iloc[0]['roc_auc_std']:.3f}\")\n",
    "    print(f\"  F1: {cv_results.iloc[0]['f1_mean']:.3f} ± {cv_results.iloc[0]['f1_std']:.3f}\")\n",
    "\n",
    "    return best_model_name, best_model\n",
    "\n",
    "best_model_name, best_model = select_best_model(cv_results, all_models)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3975194",
   "metadata": {},
   "source": [
    "###     3.3 Final Train & Test Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0bb5957a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: 2681 samples (42 positives, 1.57%)\n",
      "Test set: 671 samples (10 positives, 1.49%)\n",
      "\n",
      "Final model performance (test set)\n",
      "\n",
      "ROC-AUC Score: 0.9899\n",
      "PR-AUC Score:  0.4983\n",
      "F1 Score:       0.5000\n",
      "\n",
      "Confusion Matrix:\n",
      "[[653   8]\n",
      " [  4   6]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       661\n",
      "           1       0.43      0.60      0.50        10\n",
      "\n",
      "    accuracy                           0.98       671\n",
      "   macro avg       0.71      0.79      0.75       671\n",
      "weighted avg       0.99      0.98      0.98       671\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def final_evaluation(model, X, y, test_size=0.2, random_state=42):\n",
    "    \"\"\"\n",
    "    Final evaluation using train/test split.\n",
    "    \"\"\"\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.metrics import (\n",
    "        roc_auc_score, average_precision_score, f1_score,\n",
    "        confusion_matrix, classification_report\n",
    "    )\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=test_size, random_state=random_state, stratify=y\n",
    "    )\n",
    "    \n",
    "    print(f\"Training set: {len(X_train)} samples ({y_train.sum()} positives, {y_train.mean():.2%})\")\n",
    "    print(f\"Test set: {len(X_test)} samples ({y_test.sum()} positives, {y_test.mean():.2%})\")\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    y_test_proba = model.predict_proba(X_test)[:, 1]\n",
    "    y_test_pred = (y_test_proba >= 0.5).astype(int)\n",
    "    \n",
    "    metrics = {\n",
    "        \"roc_auc\": roc_auc_score(y_test, y_test_proba),\n",
    "        \"pr_auc\": average_precision_score(y_test, y_test_proba),\n",
    "        \"f1\": f1_score(y_test, y_test_pred),\n",
    "        \"confusion_matrix\": confusion_matrix(y_test, y_test_pred),\n",
    "        \"classification_report\": classification_report(y_test, y_test_pred)\n",
    "    }\n",
    "    \n",
    "    print()\n",
    "    print(\"Final model performance (test set)\")\n",
    "    print()\n",
    "    print(f\"ROC-AUC Score: {metrics['roc_auc']:.4f}\")\n",
    "    print(f\"PR-AUC Score:  {metrics['pr_auc']:.4f}\")\n",
    "    print(f\"F1 Score:       {metrics['f1']:.4f}\")\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(metrics['confusion_matrix'])\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(metrics['classification_report'])\n",
    "    \n",
    "    return {\n",
    "        \"model\": model,\n",
    "        \"X_test\": X_test,\n",
    "        \"y_test\": y_test,\n",
    "        \"y_test_proba\": y_test_proba,\n",
    "        \"y_test_pred\": y_test_pred,\n",
    "        \"metrics\": metrics\n",
    "    }\n",
    "\n",
    "\n",
    "final_results = final_evaluation(best_model, X, y, test_size=0.2, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e5c2163",
   "metadata": {},
   "source": [
    "### 3.4 Generate Predictions and output the final segments with predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1f7dfae5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Model trained and predictions generated: \n",
      "------------------------------------------\n",
      "   Predicted high-risk segments: 66\n",
      "   Average collision probability: 0.025\n",
      "------------------------------------------\n",
      "   Risk distribution:\n",
      "risk_category\n",
      "Low          3227\n",
      "Medium         56\n",
      "High            3\n",
      "Very High      66\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def generate_predictions(model, X, segments):\n",
    "    \"\"\"\n",
    "    Generate predictions for full dataset and add to segments GeoDataFrame.\n",
    "    \"\"\"\n",
    "    model.fit(X, y)\n",
    "    \n",
    "    y_proba = model.predict_proba(X)[:, 1]\n",
    "    y_pred = (y_proba >= 0.5).astype(int)\n",
    "    \n",
    "    segments = segments.copy()\n",
    "    segments[\"collision_probability\"] = y_proba\n",
    "    segments[\"predicted_risk\"] = y_pred\n",
    "    \n",
    "    segments[\"risk_category\"] = pd.cut(\n",
    "        segments[\"collision_probability\"],\n",
    "        bins=[0, 0.1, 0.3, 0.5, 1.0],\n",
    "        labels=[\"Low\", \"Medium\", \"High\", \"Very High\"]\n",
    "    )\n",
    "    \n",
    "    print(\" Model trained and predictions generated: \")\n",
    "    print(\"------------------------------------------\")\n",
    "    print(f\"   Predicted high-risk segments: {(segments['predicted_risk'] == 1).sum()}\")\n",
    "    print(f\"   Average collision probability: {segments['collision_probability'].mean():.3f}\")\n",
    "    print(\"------------------------------------------\")\n",
    "    print(\"   Risk distribution:\")\n",
    "    print(segments[\"risk_category\"].value_counts().sort_index())\n",
    "    \n",
    "    return segments\n",
    "\n",
    "\n",
    "segments = generate_predictions(best_model, X, segments)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
